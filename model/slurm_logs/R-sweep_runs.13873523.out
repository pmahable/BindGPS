## SLURM PROLOG ###############################################################
##    Job ID : 13873523
##  Job Name : sweep_runs
##  Nodelist : gpu2007
##      CPUs : 1
##  Mem/Node : 32000 MB
## Directory : /oscar/data/larschan/shared_data/BindGPS/model
##   Job Started : Sat Nov  8 17:18:37 EST 2025
###############################################################################
Running model parameter sweep with GAT (NO SVM)
Create sweep with ID: xpfzqhhy
Sweep URL: https://wandb.ai/bind-gps/gps-gat-model-parameter-test/sweeps/xpfzqhhy
Created sweep: xpfzqhhy
Starting 24 runs...
Original input_features shape: (137552, 7)
Unique train labels: tensor([0, 1, 2])
Training with num_classes: 3
Train Samples: 20232
Val Samples: 2601
Test Samples: 6071
cuda
Epoch 000 | loss=18.7119 | train_acc=0.6015 | val_loss=29.6957 | val_acc=0.1699
Epoch 001 | loss=13.5352 | train_acc=0.5111 | val_loss=2.4955 | val_acc=0.2599
Epoch 002 | loss=4.1645 | train_acc=0.5041 | val_loss=1.0778 | val_acc=0.4554
Epoch 003 | loss=1.8271 | train_acc=0.4857 | val_loss=1.0367 | val_acc=0.6187
Epoch 004 | loss=1.3102 | train_acc=0.5436 | val_loss=1.0308 | val_acc=0.6187
Epoch 005 | loss=1.1729 | train_acc=0.5692 | val_loss=1.0244 | val_acc=0.6187
Epoch 006 | loss=1.1155 | train_acc=0.5816 | val_loss=1.0199 | val_acc=0.6187
Epoch 007 | loss=1.0609 | train_acc=0.5897 | val_loss=1.0152 | val_acc=0.6187
Epoch 008 | loss=1.0400 | train_acc=0.5927 | val_loss=1.0094 | val_acc=0.6187
Epoch 009 | loss=1.0153 | train_acc=0.5966 | val_loss=1.0046 | val_acc=0.6187
Epoch 010 | loss=1.0018 | train_acc=0.5992 | val_loss=1.0010 | val_acc=0.6187
Epoch 011 | loss=0.9881 | train_acc=0.6016 | val_loss=1.0007 | val_acc=0.6187
Epoch 012 | loss=0.9825 | train_acc=0.6028 | val_loss=1.0001 | val_acc=0.6187
Epoch 013 | loss=0.9768 | train_acc=0.6035 | val_loss=0.9979 | val_acc=0.6187
Epoch 014 | loss=0.9687 | train_acc=0.6044 | val_loss=0.9909 | val_acc=0.6187
Epoch 015 | loss=0.9671 | train_acc=0.6049 | val_loss=0.9864 | val_acc=0.6187
Epoch 016 | loss=0.9614 | train_acc=0.6051 | val_loss=0.9824 | val_acc=0.6187
Epoch 017 | loss=0.9586 | train_acc=0.6058 | val_loss=0.9827 | val_acc=0.6187
Epoch 018 | loss=0.9545 | train_acc=0.6063 | val_loss=0.9813 | val_acc=0.6187
Epoch 019 | loss=0.9495 | train_acc=0.6061 | val_loss=0.9812 | val_acc=0.6187
Epoch 020 | loss=0.9499 | train_acc=0.6059 | val_loss=0.9809 | val_acc=0.6187
Epoch 021 | loss=0.9475 | train_acc=0.6066 | val_loss=0.9846 | val_acc=0.6187
Epoch 022 | loss=0.9470 | train_acc=0.6071 | val_loss=0.9848 | val_acc=0.6187
Epoch 023 | loss=0.9441 | train_acc=0.6071 | val_loss=0.9873 | val_acc=0.6187
Epoch 024 | loss=0.9405 | train_acc=0.6072 | val_loss=0.9890 | val_acc=0.6187
Epoch 025 | loss=0.9388 | train_acc=0.6074 | val_loss=0.9894 | val_acc=0.6187
Epoch 026 | loss=0.9390 | train_acc=0.6075 | val_loss=0.9861 | val_acc=0.6187
Epoch 027 | loss=0.9394 | train_acc=0.6072 | val_loss=0.9884 | val_acc=0.6187
Epoch 028 | loss=0.9395 | train_acc=0.6071 | val_loss=0.9905 | val_acc=0.6187
Epoch 029 | loss=0.9377 | train_acc=0.6073 | val_loss=0.9873 | val_acc=0.6187
Epoch 030 | loss=0.9360 | train_acc=0.6076 | val_loss=0.9872 | val_acc=0.6187
Epoch 031 | loss=0.9320 | train_acc=0.6078 | val_loss=0.9902 | val_acc=0.6187
Epoch 032 | loss=0.9332 | train_acc=0.6078 | val_loss=0.9897 | val_acc=0.6187
Epoch 033 | loss=0.9327 | train_acc=0.6078 | val_loss=0.9903 | val_acc=0.6187
Epoch 034 | loss=0.9306 | train_acc=0.6076 | val_loss=0.9892 | val_acc=0.6187
Epoch 035 | loss=0.9307 | train_acc=0.6075 | val_loss=0.9890 | val_acc=0.6187
Epoch 036 | loss=0.9285 | train_acc=0.6078 | val_loss=0.9894 | val_acc=0.6187
Epoch 037 | loss=0.9296 | train_acc=0.6075 | val_loss=0.9905 | val_acc=0.6187
Epoch 038 | loss=0.9286 | train_acc=0.6078 | val_loss=0.9907 | val_acc=0.6187
Epoch 039 | loss=0.9280 | train_acc=0.6085 | val_loss=0.9913 | val_acc=0.6187
Epoch 040 | loss=0.9277 | train_acc=0.6078 | val_loss=0.9893 | val_acc=0.6187
Epoch 041 | loss=0.9284 | train_acc=0.6068 | val_loss=0.9950 | val_acc=0.6187
Epoch 042 | loss=0.9268 | train_acc=0.6081 | val_loss=0.9906 | val_acc=0.6187
Epoch 043 | loss=0.9233 | train_acc=0.6086 | val_loss=0.9893 | val_acc=0.6187
Epoch 044 | loss=0.9307 | train_acc=0.6081 | val_loss=0.9948 | val_acc=0.6187
Epoch 045 | loss=0.9259 | train_acc=0.6084 | val_loss=0.9938 | val_acc=0.6187
Epoch 046 | loss=0.9254 | train_acc=0.6083 | val_loss=0.9933 | val_acc=0.6187
Epoch 047 | loss=0.9277 | train_acc=0.6076 | val_loss=0.9958 | val_acc=0.6187
Epoch 048 | loss=0.9263 | train_acc=0.6078 | val_loss=1.0005 | val_acc=0.6187
Epoch 049 | loss=0.9329 | train_acc=0.6066 | val_loss=1.0098 | val_acc=0.6187
